{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.debugger import set_trace\n",
    "import numpy as np\n",
    "#import pprint\n",
    "import sys\n",
    "if \"../\" not in sys.path:\n",
    "  sys.path.append(\"../\") \n",
    "\n",
    "from lib.envs.gridworld import GridworldEnv\n",
    "env = GridworldEnv()\n",
    "\n",
    "#from lib.envs.cliff_walking import CliffWalkingEnv\n",
    "#env = CliffWalkingEnv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_eval(policy, env, discount_factor=1.0, theta=0.00001):\n",
    "    \"\"\"\n",
    "    Evaluate a policy given an environment and a full description of the environment's dynamics.\n",
    "    \n",
    "    Args:\n",
    "        policy: [S, A] shaped matrix representing the policy.\n",
    "        env: OpenAI env. env.P represents the transition probabilities of the environment.\n",
    "            env.P[s][a] is a list of transition tuples (prob, next_state, reward, done).\n",
    "            env.nS is a number of states in the environment. \n",
    "            env.nA is a number of actions in the environment.\n",
    "        theta: We stop evaluation once our value function change is less than theta for all states.\n",
    "        discount_factor: Gamma discount factor.\n",
    "    \n",
    "    Returns:\n",
    "        Vector of length env.nS representing the value function.\n",
    "    \"\"\"\n",
    "   \n",
    "    # V = Estimate of the value function\n",
    "    # Initialize V arbitrarily, except that V (terminal) = 0\n",
    "    # In this implementation we initialize V to zeros \n",
    "    V = np.zeros(env.nS)\n",
    "    iter = 0\n",
    "    printouts = 0\n",
    "    print_factor = 1\n",
    "    while True:\n",
    "        iter += 1\n",
    "        delta = 0\n",
    "        # Loop over all states and perform an update\n",
    "        for s in range(env.nS):\n",
    "            v = 0\n",
    "            # Look at the possible next actions\n",
    "            for a, action_prob in enumerate(policy[s]):\n",
    "                # For each action available in each state\n",
    "                # look at the possible next states...\n",
    "                for  prob, next_state, reward, done in env.P[s][a]:\n",
    "                    # Calculate the expected value. Ref: Sutton Barto eq. 4.5.\n",
    "                    # Sum over all actions i each state    \n",
    "                    v += action_prob * prob * (reward + discount_factor * V[next_state])\n",
    "                    \"\"\"\n",
    "                    To think about...\n",
    "                    How to handle the cases where you are done. For example, in the cliff walking environment, \n",
    "                    if done = TRUE, do you add the values for the next_state?\n",
    "                    if done:\n",
    "                        print(\"-- -- -- -- -- -- -- -- -- -- --\")\n",
    "                        print(\"Done:\", done, \"Current state:\", s, \"Next state:\", next_state)\n",
    "                        print(\"action_prob:\", action_prob, \"prob:\", prob, \"Reward:\", reward, \"V[next_state]\", V[next_state])\n",
    "                        print(\"-- -- -- -- -- -- -- -- -- -- --\")\n",
    "                        v += action_prob * prob * reward\n",
    "                    else:\n",
    "                        v += action_prob * prob * (reward + discount_factor * V[next_state])\n",
    "                    \"\"\"\n",
    "            # Calculate How much our value function changed (across any states)\n",
    "            delta = max(delta, abs(v - V[s]))\n",
    "            # Update the value function\n",
    "            V[s] = v\n",
    "            \n",
    "        # Some printing for debugging\n",
    "        if 0 == ((iter-1) % print_factor):\n",
    "            printouts += 1\n",
    "            print(\"Value Function:\", iter, printouts, print_factor)\n",
    "            print(V)\n",
    "            if 0 == (printouts % 10):\n",
    "                print_factor *= 10\n",
    "        \n",
    "        # Stop evaluating once our value function change is below a threshold\n",
    "        if delta < theta:\n",
    "            break\n",
    "    return np.array(V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.25 0.25 0.25 0.25]\n",
      " [0.25 0.25 0.25 0.25]\n",
      " [0.25 0.25 0.25 0.25]\n",
      " [0.25 0.25 0.25 0.25]\n",
      " [0.25 0.25 0.25 0.25]\n",
      " [0.25 0.25 0.25 0.25]\n",
      " [0.25 0.25 0.25 0.25]\n",
      " [0.25 0.25 0.25 0.25]\n",
      " [0.25 0.25 0.25 0.25]\n",
      " [0.25 0.25 0.25 0.25]\n",
      " [0.25 0.25 0.25 0.25]\n",
      " [0.25 0.25 0.25 0.25]\n",
      " [0.25 0.25 0.25 0.25]\n",
      " [0.25 0.25 0.25 0.25]\n",
      " [0.25 0.25 0.25 0.25]\n",
      " [0.25 0.25 0.25 0.25]]\n"
     ]
    }
   ],
   "source": [
    "equal_dist_policy = np.ones([env.nS, env.nA]) / env.nA\n",
    "print(equal_dist_policy)\n",
    "#zeros_policy = np.zeros([env.nS, env.nA]) \n",
    "#print(zeros_policy)\n",
    "# Zeros will not work as all the action_probabilities be zero "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value Function: 1 1 1\n",
      "[ 0.        -1.        -1.25      -1.3125    -1.        -1.5\n",
      " -1.6875    -1.75      -1.25      -1.6875    -1.84375   -1.8984375\n",
      " -1.3125    -1.75      -1.8984375  0.       ]\n",
      "Value Function: 2 2 1\n",
      "[ 0.         -1.9375     -2.546875   -2.73046875 -1.9375     -2.8125\n",
      " -3.23828125 -3.40429688 -2.546875   -3.23828125 -3.56835938 -3.21777344\n",
      " -2.73046875 -3.40429688 -3.21777344  0.        ]\n",
      "Value Function: 3 3 1\n",
      "[ 0.         -2.82421875 -3.83496094 -4.17504883 -2.82421875 -4.03125\n",
      " -4.7097168  -4.87670898 -3.83496094 -4.7097168  -4.96374512 -4.26455688\n",
      " -4.17504883 -4.87670898 -4.26455688  0.        ]\n",
      "Value Function: 4 4 1\n",
      "[ 0.         -3.67260742 -5.0980835  -5.58122253 -3.67260742 -5.19116211\n",
      " -6.03242493 -6.18872833 -5.0980835  -6.03242493 -6.14849091 -5.15044403\n",
      " -5.58122253 -6.18872833 -5.15044403  0.        ]\n",
      "Value Function: 5 5 1\n",
      "[ 0.         -4.49046326 -6.30054855 -6.91293049 -4.49046326 -6.26144409\n",
      " -7.22480297 -7.36922646 -6.30054855 -7.22480297 -7.1876235  -5.9268235\n",
      " -6.91293049 -7.36922646 -5.9268235   0.        ]\n",
      "Value Function: 6 6 1\n",
      "[ 0.         -5.26311398 -7.425349   -8.15510911 -5.26311398 -7.24395847\n",
      " -8.30653936 -8.4394246  -7.425349   -8.30653936 -8.11668143 -6.62073238\n",
      " -8.15510911 -8.4394246  -6.62073238  0.        ]\n",
      "Value Function: 7 7 1\n",
      "[ 0.         -5.98310536 -8.46752571 -9.30429213 -5.98310536 -8.14482236\n",
      " -9.29211352 -9.41414066 -8.46752571 -9.29211352 -8.95642295 -7.247824\n",
      " -9.30429213 -9.41414066 -7.247824    0.        ]\n",
      "Value Function: 8 8 1\n",
      "[  0.          -6.64886336  -9.42819868 -10.3627309   -6.64886336\n",
      "  -8.97048844 -10.19231268 -10.30425206  -9.42819868 -10.19231268\n",
      "  -9.72006834  -7.8180361  -10.3627309  -10.30425206  -7.8180361\n",
      "   0.        ]\n",
      "Value Function: 9 9 1\n",
      "[  0.          -7.26188762 -10.31128247 -11.33524908  -7.26188762\n",
      "  -9.72710015 -11.01567576 -11.11830325 -10.31128247 -11.01567576\n",
      " -10.41685593  -8.33829882 -11.33524908 -11.11830325  -8.33829882\n",
      "   0.        ]\n",
      "Value Function: 10 10 1\n",
      "[  0.          -7.82506756 -11.12181872 -12.22765503  -7.82506756\n",
      " -10.42037166 -11.76933739 -11.86339862 -11.12181872 -11.76933739\n",
      " -11.0538181   -8.81387889 -12.22765503 -11.86339862  -8.81387889\n",
      "   0.        ]\n",
      "Value Function: 11 11 10\n",
      "[  0.          -8.34181448 -11.86515641 -13.04596627  -8.34181448\n",
      " -11.05557594 -12.45948727 -12.54568276 -11.86515641 -12.45948727\n",
      " -11.63668308  -9.24906118 -13.04596627 -12.54568276  -9.24906118\n",
      "   0.        ]\n",
      "Value Function: 21 12 10\n",
      "[  0.         -11.64164544 -16.60954932 -18.26818039 -11.64164544\n",
      " -15.10598845 -16.85776803 -16.89369753 -16.60954932 -16.85776803\n",
      " -15.34853106 -12.02038067 -18.26818039 -16.89369753 -12.02038067\n",
      "   0.        ]\n",
      "Value Function: 31 13 10\n",
      "[  0.         -13.01718748 -18.5870755  -20.44481467 -13.01718748\n",
      " -16.79396009 -18.6905178  -18.70549093 -18.5870755  -18.6905178\n",
      " -16.89503678 -13.17502087 -20.44481467 -18.70549093 -13.17502087\n",
      "   0.        ]\n",
      "Value Function: 41 14 10\n",
      "[  0.         -13.59042627 -19.41118296 -21.35189769 -13.59042627\n",
      " -17.49739929 -19.45429113 -19.46053098 -19.41118296 -19.45429113\n",
      " -17.53952163 -13.65620118 -21.35189769 -19.46053098 -13.65620118\n",
      "   0.        ]\n",
      "Value Function: 51 15 10\n",
      "[  0.         -13.82931573 -19.75461852 -21.72991219 -13.82931573\n",
      " -17.790548   -19.77258326 -19.77518363 -19.75461852 -19.77258326\n",
      " -17.80810191 -13.85672653 -21.72991219 -19.77518363 -13.85672653\n",
      "   0.        ]\n",
      "Value Function: 61 16 10\n",
      "[  0.         -13.92886965 -19.89774061 -21.88744458 -13.92886965\n",
      " -17.91271373 -19.90522717 -19.90631084 -19.89774061 -19.90522717\n",
      " -17.92002909 -13.94029273 -21.88744458 -19.90631084 -13.94029273\n",
      "   0.        ]\n",
      "Value Function: 71 17 10\n",
      "[  0.         -13.9703574  -19.95738479 -21.95309406 -13.9703574\n",
      " -17.96362464 -19.96050471 -19.96095632 -19.95738479 -19.96050471\n",
      " -17.96667321 -13.97511781 -21.95309406 -19.96095632 -13.97511781\n",
      "   0.        ]\n",
      "Value Function: 81 18 10\n",
      "[  0.         -13.98764685 -19.98224069 -21.98045259 -13.98764685\n",
      " -17.98484106 -19.98354088 -19.98372908 -19.98224069 -19.98354088\n",
      " -17.98611151 -13.98963069 -21.98045259 -19.98372908 -13.98963069\n",
      "   0.        ]\n"
     ]
    }
   ],
   "source": [
    "#Discount factor\n",
    "df = 1.0\n",
    "theta = 0.001\n",
    "v = policy_eval(equal_dist_policy, env, df, theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value Function:\n",
      "[  0.         -13.99330608 -19.99037659 -21.98940765 -13.99330608\n",
      " -17.99178568 -19.99108113 -19.99118312 -19.99037659 -19.99108113\n",
      " -17.99247411 -13.99438108 -21.98940765 -19.99118312 -13.99438108\n",
      "   0.        ]\n",
      "\n",
      "Reshaped Grid Value Function:\n",
      "[[  0.         -13.99330608 -19.99037659 -21.98940765]\n",
      " [-13.99330608 -17.99178568 -19.99108113 -19.99118312]\n",
      " [-19.99037659 -19.99108113 -17.99247411 -13.99438108]\n",
      " [-21.98940765 -19.99118312 -13.99438108   0.        ]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Value Function:\")\n",
    "print(v)\n",
    "print(\"\")\n",
    "\n",
    "print(\"Reshaped Grid Value Function:\")\n",
    "print(v.reshape(env.shape))\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test: Make sure the evaluated policy is what we expected\n",
    "# Gridworld\n",
    "# expected_v = np.array([0, -14, -20, -22, -14, -18, -20, -20, -20, -20, -18, -14, -22, -20, -14, 0])\n",
    "# np.testing.assert_array_almost_equal(v, expected_v, decimal=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
